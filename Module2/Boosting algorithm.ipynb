{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8fd6a8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5685798e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\n",
    "sns.set_style({'font.family':'serif', 'font.serif':'Computer Modern'})\n",
    "sns.set_context(font_scale=2, rc={\"font.size\":10,\"axes.titlesize\":20,\"axes.labelsize\":15})\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464bcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c95b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5252c463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\utente\\anaconda3\\lib\\site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\utente\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\utente\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b836f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c62670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45e96082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf72e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebfbe9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"C:/Users/Utente/OneDrive/Desktop/UNIPI - DS for Business Informatics/Data Mining_2/Progetto/df_train_processed.csv\")\n",
    "df_test = pd.read_csv(\"C:/Users/Utente/OneDrive/Desktop/UNIPI - DS for Business Informatics/Data Mining_2/Progetto/df_test_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acfcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd92d8",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95d731",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef843e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_num = df_train.select_dtypes(include=\"number\").drop(\"actor\", axis=1)\n",
    "df_train_cat = df_train.select_dtypes(include=['object'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_train_num_scaled = pd.DataFrame(scaler.fit_transform(df_train_num), columns=df_train_num.columns)\n",
    "df_train_scaled_s = pd.concat([df_train_num_scaled, df_train_cat], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e581e",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a54f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_num = df_test.select_dtypes(include=\"number\").drop(\"actor\", axis=1)\n",
    "df_test_cat = df_test.select_dtypes(include=['object'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_test_num_scaled = pd.DataFrame(scaler.fit_transform(df_test_num), columns=df_test_num.columns)\n",
    "df_test_scaled_s = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e8344d",
   "metadata": {},
   "source": [
    "# LGBM Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0750775",
   "metadata": {},
   "source": [
    "## target --> sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0349d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_s['sex'] = pd.factorize(df_train_scaled_s['sex'])[0]\n",
    "df_train_s = pd.get_dummies(df_train_scaled_s)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_s['sex'] = pd.factorize(df_test_scaled_s['sex'])[0]\n",
    "df_test_s = pd.get_dummies(df_test_scaled_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73c67881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_s.drop(['sex'], axis=1)\n",
    "y_train = df_train_s['sex']\n",
    "X_test = df_test_s.drop(['sex'], axis=1)\n",
    "y_test = df_test_s['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b834476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] subsample_for_bin is set=200000, subsample_for_bin=224482 will be ignored. Current value: subsample_for_bin=200000\n",
      "Best parameters: {'boosting_type': 'goss', 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 428, 'num_leaves': 9}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88       312\n",
      "           1       0.99      0.75      0.85       312\n",
      "\n",
      "    accuracy                           0.87       624\n",
      "   macro avg       0.89      0.87      0.87       624\n",
      "weighted avg       0.89      0.87      0.87       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50), #[0.001, 0.05, 0.1, 0.2,0.5, 0.7, ],\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc9f11",
   "metadata": {},
   "source": [
    "### Seconda grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "393b0547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'subsample_for_bin': 240000, 'num_leaves': 14, 'n_estimators': 348, 'max_depth': 4, 'learning_rate': 0.16, 'boosting_type': 'goss'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       312\n",
      "           1       0.99      0.77      0.87       312\n",
      "\n",
      "    accuracy                           0.88       624\n",
      "   macro avg       0.90      0.88      0.88       624\n",
      "weighted avg       0.90      0.88      0.88       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['goss'],\n",
    "    'n_estimators': [348,358,368,378,388,398,408,418,428,438,448,458,468,478,488,498],\n",
    "    'max_depth': [3,4,5,6,7,8,9,10,11],\n",
    "    'learning_rate': [0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17],\n",
    "    'num_leaves': [6,7,8,9,10,11,12,13,14,15,16,17],\n",
    "    \"subsample_for_bin\" : [200000,210000,220000,230000,240000,250000,260000]\n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91581d73",
   "metadata": {},
   "source": [
    "## Vocal_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19245570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled_v = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ac252b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled_v = pd.concat([df_train_num_scaled, df_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9db170a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_v['vocal_channel'] = pd.factorize(df_train_scaled_v['vocal_channel'])[0]\n",
    "df_train_v = pd.get_dummies(df_train_scaled_v)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_v['vocal_channel'] = pd.factorize(df_test_scaled_v['vocal_channel'])[0]\n",
    "df_test_v = pd.get_dummies(df_test_scaled_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f5be32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_v.drop(['vocal_channel'], axis=1)\n",
    "y_train = df_train_v['vocal_channel']\n",
    "X_test = df_test_v.drop(['vocal_channel'], axis=1)\n",
    "y_test = df_test_v['vocal_channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d0dca78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'goss', 'learning_rate': 0.32374575428176433, 'max_depth': 10, 'n_estimators': 480, 'num_leaves': 39, 'subsample_for_bin': 280077}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       360\n",
      "           1       0.95      0.99      0.97       264\n",
      "\n",
      "    accuracy                           0.97       624\n",
      "   macro avg       0.97      0.98      0.97       624\n",
      "weighted avg       0.97      0.97      0.97       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50),\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf0cb2",
   "metadata": {},
   "source": [
    "### Seconda grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75b3e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'subsample_for_bin': 290077, 'num_leaves': 41, 'n_estimators': 450, 'max_depth': 15, 'learning_rate': 0.5, 'boosting_type': 'goss'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       360\n",
      "           1       0.96      0.99      0.98       264\n",
      "\n",
      "    accuracy                           0.98       624\n",
      "   macro avg       0.98      0.98      0.98       624\n",
      "weighted avg       0.98      0.98      0.98       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['goss'],\n",
    "    'n_estimators': [400,410,420,430,440,450,460,470,480,490,500,510,520,530],\n",
    "    'max_depth': [4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "    'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "    'num_leaves': [35,36,37,38,39,40,41,42,43,44,45],\n",
    "    \"subsample_for_bin\" : [250077,260077,270077,280077,290077,300077] \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80eea24",
   "metadata": {},
   "source": [
    "## Emotional_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "802c2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled_ei = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b684fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled_ei = pd.concat([df_train_num_scaled, df_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d25c0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_ei['emotional_intensity'] = pd.factorize(df_train_scaled_ei['emotional_intensity'])[0]\n",
    "df_train_ei = pd.get_dummies(df_train_scaled_ei)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_ei['emotional_intensity'] = pd.factorize(df_test_scaled_ei['emotional_intensity'])[0]\n",
    "df_test_ei = pd.get_dummies(df_test_scaled_ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5199398",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_ei.drop(['emotional_intensity'], axis=1)\n",
    "y_train = df_train_ei['emotional_intensity']\n",
    "X_test = df_test_ei.drop(['emotional_intensity'], axis=1)\n",
    "y_test = df_test_ei['emotional_intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70763361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'dart', 'learning_rate': 0.32374575428176433, 'max_depth': 28, 'n_estimators': 209, 'num_leaves': 10, 'subsample_for_bin': 287455}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76       336\n",
      "           1       0.70      0.88      0.78       288\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.78      0.78      0.77       624\n",
      "weighted avg       0.79      0.77      0.77       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50),\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf59ae",
   "metadata": {},
   "source": [
    "### Seconda Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5a0d42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'subsample_for_bin': 257455, 'num_leaves': 11, 'n_estimators': 269, 'max_depth': 25, 'learning_rate': 0.2, 'boosting_type': 'dart'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       336\n",
      "           1       0.70      0.81      0.75       288\n",
      "\n",
      "    accuracy                           0.75       624\n",
      "   macro avg       0.75      0.75      0.75       624\n",
      "weighted avg       0.76      0.75      0.75       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['dart'],\n",
    "    'n_estimators': [179,189,199,209,219,229,239,249,259,269],\n",
    "    'max_depth': [25,26,27,28,28,30,31,32,33,34,35,36,37,38,39],\n",
    "    'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
    "    'num_leaves': [5,6,7,8,9,10,11,12,13,14,15],\n",
    "    \"subsample_for_bin\" : [257455,267455,277455,287455,297455,307455,317455,327455,337455]\n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e51d7",
   "metadata": {},
   "source": [
    "## Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c459fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled_e = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38a03981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled_e = pd.concat([df_train_num_scaled, df_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ac56f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_e['emotion'] = pd.factorize(df_train_scaled_e['emotion'])[0]\n",
    "df_train_e = pd.get_dummies(df_train_scaled_e)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_e['emotion'] = pd.factorize(df_test_scaled_e['emotion'])[0]\n",
    "df_test_e = pd.get_dummies(df_test_scaled_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9799a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_e.drop(['emotion'], axis=1)\n",
    "y_train = df_train_e['emotion']\n",
    "X_test = df_test_e.drop(['emotion'], axis=1)\n",
    "y_test = df_test_e['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "931438c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.3906939937054613, 'max_depth': 43, 'n_estimators': 206, 'num_leaves': 19, 'subsample_for_bin': 261228}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.42      0.44        48\n",
      "           1       0.57      0.65      0.60        96\n",
      "           2       0.51      0.36      0.42        96\n",
      "           3       0.39      0.36      0.38        96\n",
      "           4       0.54      0.78      0.64        96\n",
      "           5       0.56      0.36      0.44        96\n",
      "           6       0.42      0.44      0.43        48\n",
      "           7       0.35      0.46      0.40        48\n",
      "\n",
      "    accuracy                           0.49       624\n",
      "   macro avg       0.48      0.48      0.47       624\n",
      "weighted avg       0.49      0.49      0.48       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50),\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c8ec45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'subsample_for_bin': 251228, 'num_leaves': 18, 'n_estimators': 256, 'max_depth': 36, 'learning_rate': 0.2, 'boosting_type': 'gbdt'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.40      0.44        48\n",
      "           1       0.54      0.70      0.61        96\n",
      "           2       0.51      0.38      0.43        96\n",
      "           3       0.42      0.30      0.35        96\n",
      "           4       0.53      0.79      0.64        96\n",
      "           5       0.58      0.33      0.42        96\n",
      "           6       0.42      0.50      0.46        48\n",
      "           7       0.36      0.50      0.42        48\n",
      "\n",
      "    accuracy                           0.49       624\n",
      "   macro avg       0.48      0.49      0.47       624\n",
      "weighted avg       0.50      0.49      0.48       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'n_estimators': [176,186,196,206,216,226,236,246,256,266],\n",
    "    'max_depth': [35,36,37,38,39,340,41,42,43,44,45,46,47],\n",
    "    'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
    "    'num_leaves': [14,15,16,17,18,19,20,21,22,23,24,25],\n",
    "    \"subsample_for_bin\" : [221228,231228,241228,251228,261228,271228,272228,282228,292228]\n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cfcea6",
   "metadata": {},
   "source": [
    "# Utilizzo della conversione automatica del modello per le categoriche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c83b30",
   "metadata": {},
   "source": [
    "## Variabile target --> emotional_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec5956",
   "metadata": {},
   "source": [
    "LGBMClassifier() utilizza per la conversione delle categoriche il metodo Fisher, che almeno teoricamente, dovrebbe performare meglio della one-hot encoding \n",
    "https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e43f5",
   "metadata": {},
   "source": [
    "L'unica azione di preprocessing con è la standardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9c8ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled_ei = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18866cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled_ei = pd.concat([df_train_num_scaled, df_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "465cad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qua trasformo le categoriche (che normalmente assumo il datatype \"object\") nel datatype \"category\". L'operazione viene svolta \n",
    "# sia per il train che per il test set, escludendo la variabile target.\n",
    "cat_cols = ['vocal_channel', 'emotion', 'statement', 'repetition', 'sex']\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_train_scaled_s[col] = df_train_scaled_s[col].astype('category')\n",
    "    df_test_scaled_s[col] = df_test_scaled_s[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fbc47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_scaled_ei.drop(['emotional_intensity'], axis=1)\n",
    "y_train = df_train_scaled_ei['emotional_intensity']\n",
    "X_test = df_test_scaled_ei.drop(['emotional_intensity'], axis=1)\n",
    "y_test = df_test_scaled_ei['emotional_intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd9c0271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013257113655901081, 'max_depth': 15, 'n_estimators': 282, 'num_leaves': 7, 'subsample_for_bin': 258053}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.80      0.71      0.76       336\n",
      "      strong       0.70      0.80      0.75       288\n",
      "\n",
      "    accuracy                           0.75       624\n",
      "   macro avg       0.75      0.75      0.75       624\n",
      "weighted avg       0.76      0.75      0.75       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50),\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee080f",
   "metadata": {},
   "source": [
    "## Variabile target --> Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7e961d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled_s = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56758b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled_s = pd.concat([df_train_num_scaled, df_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db4d3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qua trasformo le categoriche (che normalmente assumo il datatype \"object\") nel datatype \"category\". L'operazione viene svolta \n",
    "# sia per il train che per il test set, escludendo la variabile target.\n",
    "cat_cols = ['vocal_channel', 'emotion', 'statement', 'repetition', 'emotional_intensity']\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_train_scaled_s[col] = df_train_scaled_s[col].astype('category')\n",
    "    df_test_scaled_s[col] = df_test_scaled_s[col].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2eb9f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_scaled_s.drop(['sex'], axis=1)\n",
    "y_train = df_train_scaled_s['sex']\n",
    "X_test = df_test_scaled_s.drop(['sex'], axis=1)\n",
    "y_test = df_test_scaled_s['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "248b6429",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'dart', 'learning_rate': 0.22229964825261933, 'max_depth': 6, 'n_estimators': 359, 'num_leaves': 33, 'subsample_for_bin': 245758}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.99      0.77      0.86       312\n",
      "           M       0.81      0.99      0.89       312\n",
      "\n",
      "    accuracy                           0.88       624\n",
      "   macro avg       0.90      0.88      0.88       624\n",
      "weighted avg       0.90      0.88      0.88       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50),\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64182c64",
   "metadata": {},
   "source": [
    "## Variabile target --> Vocal_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31eed80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled_v = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9247eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled_v = pd.concat([df_train_num_scaled, df_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2d4249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qua trasformo le categoriche (che normalmente assumo il datatype \"object\") nel datatype \"category\". L'operazione viene svolta \n",
    "# sia per il train che per il test set, escludendo la variabile target.\n",
    "cat_cols = ['sex', 'emotion', 'statement', 'repetition', 'emotional_intensity']\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_train_scaled_v[col] = df_train_scaled_v[col].astype('category')\n",
    "    df_test_scaled_v[col] = df_test_scaled_v[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7f2ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_scaled_v.drop(['vocal_channel'], axis=1)\n",
    "y_train = df_train_scaled_v['vocal_channel']\n",
    "X_test = df_test_scaled_v.drop(['vocal_channel'], axis=1)\n",
    "y_test = df_test_scaled_v['vocal_channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54756dc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'dart', 'learning_rate': 0.2682695795279725, 'max_depth': 39, 'n_estimators': 313, 'num_leaves': 48, 'subsample_for_bin': 248747}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        song       0.95      0.99      0.97       264\n",
      "      speech       0.99      0.96      0.97       360\n",
      "\n",
      "    accuracy                           0.97       624\n",
      "   macro avg       0.97      0.97      0.97       624\n",
      "weighted avg       0.97      0.97      0.97       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50),\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=75, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e7eec",
   "metadata": {},
   "source": [
    "## Variabile target --> Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "751cac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled_e = pd.concat([df_test_num_scaled, df_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11c32128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled_e = pd.concat([df_train_num_scaled, df_train_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9861b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qua trasformo le categoriche (che normalmente assumo il datatype \"object\") nel datatype \"category\". L'operazione viene svolta \n",
    "# sia per il train che per il test set, escludendo la variabile target.\n",
    "cat_cols = ['sex', 'vocal_channel', 'statement', 'repetition', 'emotional_intensity']\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_train_scaled_e[col] = df_train_scaled_e[col].astype('category')\n",
    "    df_test_scaled_e[col] = df_test_scaled_e[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0f03cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_scaled_e.drop(['emotion'], axis=1)\n",
    "y_train = df_train_scaled_e['emotion']\n",
    "X_test = df_test_scaled_e.drop(['emotion'], axis=1)\n",
    "y_test = df_test_scaled_e['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf6e69e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.3906939937054613, 'max_depth': 43, 'n_estimators': 206, 'num_leaves': 19, 'subsample_for_bin': 261228}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.54      0.78      0.64        96\n",
      "        calm       0.57      0.65      0.60        96\n",
      "     disgust       0.42      0.44      0.43        48\n",
      "     fearful       0.56      0.36      0.44        96\n",
      "       happy       0.51      0.36      0.42        96\n",
      "     neutral       0.47      0.42      0.44        48\n",
      "         sad       0.39      0.36      0.38        96\n",
      "   surprised       0.35      0.46      0.40        48\n",
      "\n",
      "    accuracy                           0.49       624\n",
      "   macro avg       0.48      0.48      0.47       624\n",
      "weighted avg       0.49      0.49      0.48       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart','goss'],\n",
    "    'n_estimators': randint(low=50, high=500),\n",
    "    'max_depth': randint(low=3, high=50),\n",
    "    'learning_rate': np.logspace(-4, 0, 50),\n",
    "    'num_leaves': randint(low=5, high=50),\n",
    "    \"subsample_for_bin\" : randint(low=200000, high=300000) \n",
    "}\n",
    "\n",
    "clf = LGBMClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f62596",
   "metadata": {},
   "source": [
    "Si nota una peggioramento dei modelli utilizzando la trasformazione delle categoriali integrata nel modello, anche se secondo la teoria (stesso link riportato sopra)dovrebbe essere migliore. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1964f5",
   "metadata": {},
   "source": [
    "# HistGradientBoostingClassifier ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932d766",
   "metadata": {},
   "source": [
    "Il prof aveva sottolineato come per questo classificatore non fosse neanche necessario fare la grid perchè avrebbe performato bene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417bbfe0",
   "metadata": {},
   "source": [
    "## target --> sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03100989",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_s['sex'] = pd.factorize(df_train_scaled_s['sex'])[0]\n",
    "df_train_s = pd.get_dummies(df_train_scaled_s)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_s['sex'] = pd.factorize(df_test_scaled_s['sex'])[0]\n",
    "df_test_s = pd.get_dummies(df_test_scaled_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9385d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_s.drop(['sex'], axis=1)\n",
    "y_train = df_train_s['sex']\n",
    "X_test = df_test_s.drop(['sex'], axis=1)\n",
    "y_test = df_test_s['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "651da068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'l2_regularization': 0.12648552168552957, 'learning_rate': 0.019306977288832496, 'loss': 'binary_crossentropy', 'max_depth': 17, 'max_iter': 156, 'max_leaf_nodes': 17}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       312\n",
      "           1       0.99      0.77      0.87       312\n",
      "\n",
      "    accuracy                           0.88       624\n",
      "   macro avg       0.90      0.88      0.88       624\n",
      "weighted avg       0.90      0.88      0.88       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"loss\" : [\"binary_crossentropy\"],\n",
    "    \"learning_rate\": np.logspace(-4, 0, 50),\n",
    "    \"max_depth\": randint(low=3, high=50),\n",
    "    \"max_iter\": randint(low=50, high=500),\n",
    "    \"max_leaf_nodes\": randint(low=10, high=50),\n",
    "    \"l2_regularization\": np.logspace(-4, 0, 50)\n",
    "}\n",
    "\n",
    "clf = HistGradientBoostingClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb39daf",
   "metadata": {},
   "source": [
    "## Target --> vocal channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d519c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_v['vocal_channel'] = pd.factorize(df_train_scaled_v['vocal_channel'])[0]\n",
    "df_train_v = pd.get_dummies(df_train_scaled_v)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_v['vocal_channel'] = pd.factorize(df_test_scaled_v['vocal_channel'])[0]\n",
    "df_test_v = pd.get_dummies(df_test_scaled_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cedb1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_v.drop(['vocal_channel'], axis=1)\n",
    "y_train = df_train_v['vocal_channel']\n",
    "X_test = df_test_v.drop(['vocal_channel'], axis=1)\n",
    "y_test = df_test_v['vocal_channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53aa4296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'l2_regularization': 0.004291934260128779, 'learning_rate': 0.12648552168552957, 'loss': 'binary_crossentropy', 'max_depth': 21, 'max_iter': 264, 'max_leaf_nodes': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       360\n",
      "           1       0.94      0.99      0.96       264\n",
      "\n",
      "    accuracy                           0.97       624\n",
      "   macro avg       0.96      0.97      0.97       624\n",
      "weighted avg       0.97      0.97      0.97       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"loss\" : [\"binary_crossentropy\"],\n",
    "    \"learning_rate\": np.logspace(-4, 0, 50),\n",
    "    \"max_depth\": randint(low=3, high=50),\n",
    "    \"max_iter\": randint(low=50, high=500),\n",
    "    \"max_leaf_nodes\": randint(low=10, high=50),\n",
    "    \"l2_regularization\": np.logspace(-4, 0, 50)\n",
    "}\n",
    "\n",
    "clf = HistGradientBoostingClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2a6f1",
   "metadata": {},
   "source": [
    "## Target --> emotional_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73ea0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_ei['emotional_intensity'] = pd.factorize(df_train_scaled_ei['emotional_intensity'])[0]\n",
    "df_train_ei = pd.get_dummies(df_train_scaled_ei)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_ei['emotional_intensity'] = pd.factorize(df_test_scaled_ei['emotional_intensity'])[0]\n",
    "df_test_ei = pd.get_dummies(df_test_scaled_ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d5fd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_ei.drop(['emotional_intensity'], axis=1)\n",
    "y_train = df_train_ei['emotional_intensity']\n",
    "X_test = df_test_ei.drop(['emotional_intensity'], axis=1)\n",
    "y_test = df_test_ei['emotional_intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a93ea752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'l2_regularization': 0.004291934260128779, 'learning_rate': 0.12648552168552957, 'loss': 'binary_crossentropy', 'max_depth': 21, 'max_iter': 264, 'max_leaf_nodes': 20}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       336\n",
      "           1       0.74      0.73      0.73       288\n",
      "\n",
      "    accuracy                           0.75       624\n",
      "   macro avg       0.75      0.75      0.75       624\n",
      "weighted avg       0.75      0.75      0.75       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"loss\" : [\"binary_crossentropy\"],\n",
    "    \"learning_rate\": np.logspace(-4, 0, 50),\n",
    "    \"max_depth\": randint(low=3, high=50),\n",
    "    \"max_iter\": randint(low=50, high=500),\n",
    "    \"max_leaf_nodes\": randint(low=10, high=50),\n",
    "    \"l2_regularization\": np.logspace(-4, 0, 50)\n",
    "}\n",
    "\n",
    "clf = HistGradientBoostingClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46640a80",
   "metadata": {},
   "source": [
    "## target --> emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2705396",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-hot encoding\n",
    "\n",
    "#### Train \n",
    "\n",
    "df_train_scaled_e['emotion'] = pd.factorize(df_train_scaled_e['emotion'])[0]\n",
    "df_train_e = pd.get_dummies(df_train_scaled_e)\n",
    "\n",
    "#### Test\n",
    "\n",
    "df_test_scaled_e['emotion'] = pd.factorize(df_test_scaled_e['emotion'])[0]\n",
    "df_test_e = pd.get_dummies(df_test_scaled_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d7f7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_e.drop(['emotion'], axis=1)\n",
    "y_train = df_train_e['emotion']\n",
    "X_test = df_test_e.drop(['emotion'], axis=1)\n",
    "y_test = df_test_e['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9e86c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'l2_regularization': 0.0002559547922699536, 'learning_rate': 0.22229964825261933, 'loss': 'categorical_crossentropy', 'max_depth': 6, 'max_iter': 359, 'max_leaf_nodes': 38}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.31      0.39        48\n",
      "           1       0.52      0.68      0.59        96\n",
      "           2       0.47      0.40      0.43        96\n",
      "           3       0.41      0.33      0.37        96\n",
      "           4       0.48      0.76      0.59        96\n",
      "           5       0.59      0.39      0.47        96\n",
      "           6       0.54      0.42      0.47        48\n",
      "           7       0.35      0.46      0.40        48\n",
      "\n",
      "    accuracy                           0.48       624\n",
      "   macro avg       0.49      0.47      0.46       624\n",
      "weighted avg       0.49      0.48      0.47       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"loss\" : [\"categorical_crossentropy\"],  # categorical_crossentropy per una multiclass classification\n",
    "    \"learning_rate\": np.logspace(-4, 0, 50),\n",
    "    \"max_depth\": randint(low=3, high=50),\n",
    "    \"max_iter\": randint(low=50, high=500),\n",
    "    \"max_leaf_nodes\": randint(low=10, high=50),\n",
    "    \"l2_regularization\": np.logspace(-4, 0, 50)\n",
    "}\n",
    "\n",
    "clf = HistGradientBoostingClassifier()\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_distribs, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_clf = random_search.best_estimator_ \n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2cd7f9",
   "metadata": {},
   "source": [
    "# note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbf0db",
   "metadata": {},
   "source": [
    "Ho provato anche ad utilizzare la XGBoost, ho avuto difficoltà perchè, pur stringendo al massimo i parametri, il classificatore non gira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f36e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
